{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96777c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset as TDataset, DataLoader as TDataloader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import math\n",
    "import random\n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset as TGDataset, Data as TGData\n",
    "from torch_geometric.loader import DataLoader as TGDataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric import transforms as T\n",
    "from torch_geometric.nn import GCNConv,Linear,GATConv,GATv2Conv,SAGEConv, GATConv,ChebConv\n",
    "from torch_geometric.nn import GraphConv, TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.nn.pool.topk_pool import topk,filter_adj\n",
    "LAYERS = {\n",
    "    GCNConv:\"GCNConv\",\n",
    "    GATConv: \"GATConv\",\n",
    "    SAGEConv:\"SAGEConv\",\n",
    "    ChebConv:\"ChebConv\"\n",
    "}\n",
    "\n",
    "\n",
    "from sklearn.neighbors import radius_neighbors_graph, kneighbors_graph\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "import scipy.spatial.distance\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "from CloudPointsPreprocessing import * \n",
    "from FeatureConcatModel import * \n",
    "from GraphPreprocessing import *\n",
    "from PointNet import *\n",
    "from PointNetBasedGraphPoolingModel import *\n",
    "from ReportVisualization import * \n",
    "from SelfAttentionGraphPooling import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcb1750",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_global = Path(\"ModelNet10\")\n",
    "dataset_pointcloud_test = PointCloudData(path_global, valid=True, folder='test',force_to_cal=False)\n",
    "dataset_pointcloud_train = PointCloudData(path_global, force_to_cal=False)\n",
    "\n",
    "dataset_pointcloud_train_loader = TDataloader(dataset=dataset_pointcloud_train, batch_size=32, shuffle=True)\n",
    "dataset_pointcloud_test_loader = TDataloader(dataset=dataset_pointcloud_test, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da5e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestPerfomanceCustom(model,loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0.\n",
    "        loss = 0.\n",
    "        model = model.to(\"cuda\")\n",
    "        for data in loader:\n",
    "            outputs, m3x3, m64x64 = model(data)\n",
    "            labels = data['category'].to(\"cuda\")\n",
    "            pred = outputs.max(dim=1)[1]\n",
    "            correct += pred.eq(labels).sum().item()\n",
    "            \n",
    "            loss += PointNetLoss(outputs, labels, m3x3, m64x64,defualt_dim=10).item()\n",
    "            \n",
    "    return correct / len(loader.dataset),loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def TrainCustom(model, train_loader, val_loader,lr=0.01,weight_decay=0.0005, epochs=30, name=\"PointNet\"):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    size_all_mb = round(size_all_mb,3)\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_train = []\n",
    "    acc_train = []\n",
    "\n",
    "    loss_val = []\n",
    "    acc_val = []\n",
    "    for epoch in range(epochs): \n",
    "        model.train()\n",
    "        \n",
    "        for i, data in tqdm(enumerate(train_loader, 0)):\n",
    "            optimizer.zero_grad()\n",
    "            outputs, m3x3, m64x64 = model(data)\n",
    "            labels = data['category'].to(device)\n",
    "            loss = PointNetLoss(outputs, labels, m3x3, m64x64,defualt_dim=10)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "        val_acc,val_loss = TestPerfomanceCustom(model,val_loader)\n",
    "        train_acc,train_loss = TestPerfomanceCustom(model,train_loader)\n",
    "        \n",
    "        acc_val.append(val_acc)\n",
    "        loss_val.append(val_loss)\n",
    "\n",
    "        acc_train.append(train_acc)\n",
    "        loss_train.append(train_loss)    \n",
    "\n",
    "        print(\"Epoch: {0} | Train Loss: {1} | Train Acc: {2} | Val Loss: {3} | Val Acc: {4}\".format(epoch,train_loss,train_acc,val_loss,val_acc,size_all_mb))\n",
    "        \n",
    "    test_acc = max(acc_val)\n",
    "    \n",
    "    \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.rcParams['figure.figsize']= (21,5)\n",
    "    h,w = 1,2\n",
    "    plt.subplot(h,w,1)\n",
    "    plt.plot(loss_train,label=\"Train loss\")\n",
    "    plt.plot(loss_val,label=\"Validation loss\")\n",
    "    plt.title(\"Loss Report | {0} | ModelSize: {1} MB\".format(name,size_all_mb))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"NLLLoss\")\n",
    "    plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    plt.subplot(h,w,2)\n",
    "    plt.plot(acc_train,label=\"Train Accuracy\")\n",
    "    plt.plot(acc_val,label=\"Validation Accuracy\")\n",
    "    plt.title(\"Accuracy Report | Test Accuracy: {0}%\".format(round(test_acc*100,2)))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"./{0}.png\".format(name))\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    return round(test_acc*100,2),model\n",
    "\n",
    "model = FeatureConcatModel() \n",
    "acc,model = TrainCustom(model,dataset_pointcloud_train_loader,dataset_pointcloud_test_loader,lr=0.005,weight_decay=0.0005,epochs=60,name=\"FeatureConcatModel\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
