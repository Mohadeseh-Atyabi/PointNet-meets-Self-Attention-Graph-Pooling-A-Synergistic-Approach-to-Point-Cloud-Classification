{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96777c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset as TDataset, DataLoader as TDataloader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import math\n",
    "import random\n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset as TGDataset, Data as TGData\n",
    "from torch_geometric.loader import DataLoader as TGDataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric import transforms as T\n",
    "from torch_geometric.nn import GCNConv,Linear,GATConv,GATv2Conv,SAGEConv, GATConv,ChebConv\n",
    "from torch_geometric.nn import GraphConv, TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.nn.pool.topk_pool import topk,filter_adj\n",
    "LAYERS = {\n",
    "    GCNConv:\"GCNConv\",\n",
    "    GATConv: \"GATConv\",\n",
    "    SAGEConv:\"SAGEConv\",\n",
    "    ChebConv:\"ChebConv\"\n",
    "}\n",
    "\n",
    "\n",
    "from sklearn.neighbors import radius_neighbors_graph, kneighbors_graph\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "import scipy.spatial.distance\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "from CloudPointsPreprocessing import * \n",
    "from FeatureConcatModel import * \n",
    "from GraphPreprocessing import *\n",
    "from PointNet import *\n",
    "from PointNetBasedGraphPoolingModel import *\n",
    "from ReportVisualization import * \n",
    "from SelfAttentionGraphPooling import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcb1750",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_global = Path(\"ModelNet10\")\n",
    "dataset_pointcloud_test = PointCloudData(path_global, valid=True, folder='test',force_to_cal=False)\n",
    "dataset_pointcloud_train = PointCloudData(path_global, force_to_cal=False)\n",
    "\n",
    "dataset_pointcloud_train_loader = TDataloader(dataset=dataset_pointcloud_train, batch_size=32, shuffle=True)\n",
    "dataset_pointcloud_test_loader = TDataloader(dataset=dataset_pointcloud_test, batch_size=64)\n",
    "\n",
    "\n",
    "\n",
    "dataset_graph_test = PointCloudGraph(dataset_pointcloud_test)\n",
    "dataset_graph_train = PointCloudGraph(dataset_pointcloud_train)\n",
    "TrainSet,ValidationSet,TestSet = GetSets(dataset_graph_train,0.99,0.01)\n",
    "BatchSize = 32\n",
    "TrainLoader = TGDataLoader(TrainSet, batch_size=BatchSize, shuffle=True)\n",
    "ValidationLoader = TGDataLoader(ValidationSet,batch_size=BatchSize,shuffle=False)\n",
    "TestLoader = TGDataLoader(dataset_graph_test,batch_size=BatchSize,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c335206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestPerformance(model,loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0.\n",
    "        loss = 0.\n",
    "        for data in loader:\n",
    "            data = ConvertBatchToGraph(data)\n",
    "            data = data.to(\"cuda\")\n",
    "            model = model.to(\"cuda\")\n",
    "            out = model(data)\n",
    "            pred = out.max(dim=1)[1]\n",
    "            correct += pred.eq(data.y).sum().item()\n",
    "            loss += F.cross_entropy(out,data.y).item()\n",
    "    return correct / len(loader.dataset),loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def Train(model,TrainLoader,ValidationLoader,epoch:int,lr=0.01,weight_decay=5e-4,show=True,name=\"Self-Attention Graph Pooling\"):\n",
    "    device = \"cuda\"\n",
    "    model = model.to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    model.train()\n",
    "    loss_train = []\n",
    "    acc_train = []\n",
    "\n",
    "    loss_val = []\n",
    "    acc_val = []\n",
    "\n",
    "    acc_test = []\n",
    "\n",
    "    min_loss = 1e10\n",
    "    patience = 0\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    size_all_mb = round(size_all_mb,3)\n",
    "    print(\"Model Size: {0} MB\".format(size_all_mb))\n",
    "\n",
    "    for ite in range(epoch):\n",
    "        model.train()\n",
    "        for i, data in tqdm(enumerate(TrainLoader)):\n",
    "            data = ConvertBatchToGraph(data)\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            data = data.to(\"cuda\")\n",
    "            model = model.to(\"cuda\")\n",
    "            out = model(data)\n",
    "            loss = F.cross_entropy(out, data.y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        val_acc,val_loss = TestPerformance(model,ValidationLoader)\n",
    "        train_acc,train_loss = TestPerformance(model,TrainLoader)\n",
    "        \n",
    "        acc_val.append(val_acc)\n",
    "        loss_val.append(val_loss)\n",
    "\n",
    "        acc_train.append(train_acc)\n",
    "        loss_train.append(train_loss)\n",
    "        \n",
    "        \n",
    "        print(\"Epoch: {0} | Train Loss: {1} | Train Acc: {2} | Val Loss: {3} | Val Acc: {4}\".format(ite,train_loss,train_acc,val_loss,val_acc,size_all_mb))\n",
    "    \n",
    "    test_acc = max(acc_val)\n",
    "    if show:\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        plt.rcParams['figure.figsize']= (21,5)\n",
    "        h,w = 1,2\n",
    "        plt.subplot(h,w,1)\n",
    "        plt.plot(loss_train,label=\"Train loss\")\n",
    "        plt.plot(loss_val,label=\"Validation loss\")\n",
    "        plt.title(\"Loss Report | {0} | ModelSize: {1} MB\".format(name,size_all_mb))\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Cross Entropy Loss\")\n",
    "        plt.legend()\n",
    "        #plt.show()\n",
    "\n",
    "        plt.subplot(h,w,2)\n",
    "        plt.plot(acc_train,label=\"Train Accuracy\")\n",
    "        plt.plot(acc_val,label=\"Validation Accuracy\")\n",
    "        plt.title(\"Accuracy Report | Test Accuracy: {0}%\".format(round(test_acc*100,2)))\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"./{0}.png\".format(name))\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "    return round(test_acc*100,2),model\n",
    "\n",
    "\n",
    "MAINargs = {\n",
    "    \"SAGPoolNet_dataset_features\":10,\n",
    "    \"out_channels\":1,\n",
    "    \"is_hierarchical\":True,\n",
    "    \"use_w_for_concat\":True,\n",
    "    \"pooling_ratio\":0.25,\n",
    "    \"p_dropout\":0.25,\n",
    "    \"Conv\":GATConv,\n",
    "    \"heads\":6,\n",
    "    \"concat\":False,\n",
    "    \"send_feature\":False\n",
    "}\n",
    "\n",
    "\n",
    "model = SAGPoolNet(**MAINargs)\n",
    "acc,model = Train(model,TrainLoader=dataset_pointcloud_train_loader,ValidationLoader=dataset_pointcloud_test_loader,\n",
    "            epoch=60,lr=0.01,weight_decay=0.0005,show=True,name=\"Self-Attention Graph Pooling\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestPerfomancePointNet(model,loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0.\n",
    "        loss = 0.\n",
    "        for data in loader:\n",
    "            inputs, labels = data['pointcloud'].to(\"cuda:0\").float(), data['category'].to(\"cuda:0\")\n",
    "            inputs = inputs.to(\"cuda\")\n",
    "            labels = labels.to(\"cuda\")\n",
    "            model = model.to(\"cuda\")\n",
    "            out,_,__ = model(inputs.transpose(1,2))\n",
    "            pred = out.max(dim=1)[1]\n",
    "            correct += pred.eq(labels).sum().item()\n",
    "            loss += PointNetLoss(out, labels, _, __).item()\n",
    "            \n",
    "    return correct / len(loader.dataset),loss / len(loader.dataset)\n",
    "\n",
    "def TrainPointNet(model, train_loader, val_loader,lr=0.01,weight_decay=0.0005, epochs=30, name=\"PointNet\"):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    size_all_mb = round(size_all_mb,3)\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_train = []\n",
    "    acc_train = []\n",
    "\n",
    "    loss_val = []\n",
    "    acc_val = []\n",
    "    for epoch in range(epochs): \n",
    "        model.train()\n",
    "        \n",
    "        for i, data in tqdm(enumerate(train_loader, 0)):\n",
    "            inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, m3x3, m64x64 = model(inputs.transpose(1,2))\n",
    "            loss = PointNetLoss(outputs, labels, m3x3, m64x64)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "        val_acc,val_loss = TestPerfomancePointNet(model,val_loader)\n",
    "        train_acc,train_loss = TestPerfomancePointNet(model,train_loader)\n",
    "        \n",
    "        acc_val.append(val_acc)\n",
    "        loss_val.append(val_loss)\n",
    "\n",
    "        acc_train.append(train_acc)\n",
    "        loss_train.append(train_loss)    \n",
    "\n",
    "        print(\"Epoch: {0} | Train Loss: {1} | Train Acc: {2} | Val Loss: {3} | Val Acc: {4}\".format(epoch,train_loss,train_acc,val_loss,val_acc,size_all_mb))\n",
    "        \n",
    "    test_acc = max(acc_val)\n",
    "    \n",
    "    \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.rcParams['figure.figsize']= (21,5)\n",
    "    h,w = 1,2\n",
    "    plt.subplot(h,w,1)\n",
    "    plt.plot(loss_train,label=\"Train loss\")\n",
    "    plt.plot(loss_val,label=\"Validation loss\")\n",
    "    plt.title(\"Loss Report | {0} | ModelSize: {1} MB\".format(name,size_all_mb))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"NLLLoss\")\n",
    "    plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    plt.subplot(h,w,2)\n",
    "    plt.plot(acc_train,label=\"Train Accuracy\")\n",
    "    plt.plot(acc_val,label=\"Validation Accuracy\")\n",
    "    plt.title(\"Accuracy Report | Test Accuracy: {0}%\".format(round(test_acc*100,2)))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"./{0}.png\".format(name))\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    return round(test_acc*100,2),model\n",
    "\n",
    "pointnet = PointNet()\n",
    "acc,model = TrainPointNet(pointnet,dataset_pointcloud_train_loader,dataset_pointcloud_test_loader,lr=0.001,weight_decay=0.0005,epochs=60,name=\"PointNet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec162f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
